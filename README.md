# ğŸ¥ WhisperHealth - Your AI Medical Assistant ğŸ¤–ğŸ©º
**WhisperHealth** is an AI-powered multimodal medical assistant chatbot, combining **Vision**, **Voice**, and **Natural Language Understanding**. Designed with real-time voice interaction, image analysis, and context-aware medical responses, this AI bot aims to assist users with medical-related queries through a conversational interface. Here I have built a multimodal AI chatbot using LLaMA3 Vision, OpenAI Whisper, and Groq LLMs for real-time medical Q&A.

Integrated speech-to-text, image analysis, and LLM inference to generate voice-based medical guidance.

Designed a voice-enabled UI with Gradio; deployed live on Hugging Face Spaces.

Technologies: Python, Whisper, Gradio, Groq API, gTTS, ffmpeg, .env, Hugging Face.

ğŸŒ **[Live Demo on Hugging Face Spaces](https://huggingface.co/spaces/Sharvari19/WhisperHealth-AI-Medical-Chatbot)**

---

## ğŸ§  Features

- ğŸ™ï¸ Voice-based patient interaction using speech recognition.
- ğŸ‘ï¸ Vision capabilities using LLaMA 3 Vision for image-based queries.
- ğŸ’¬ Conversational AI using GROQ API for fast, accurate LLM inference.
- ğŸ—£ï¸ Text-to-Speech response via gTTS.
- ğŸŒ Clean and intuitive Gradio UI for seamless interaction.

---

## ğŸ› ï¸ Tech Stack

| Layer            | Tool / Library         |
|------------------|------------------------|
| LLM Inference    | GROQ API               |
| Vision Model     | LLaMA 3 Vision         |
| Transcription    | OpenAI Whisper         |
| Text to Speech   | gTTS (or ElevenLabs )  |
| UI Layer         | Gradio                 |
| Language         | Python                 |
| Dev Environment  | VS Code                |

---

## ğŸ—‚ï¸ Project Structure

```bash
ğŸ“ ai-medical-chatbot/
â”‚
â”œâ”€â”€ brain_of_the_doctor.py         # Multimodal model handling (Vision + LLM)
â”œâ”€â”€ voice_of_the_patient.py        # Handles recording and transcription
â”œâ”€â”€ voice_of_the_doctor.py         # Text-to-speech generation
â”œâ”€â”€ app.py                         # Main Gradio app interface
â”œâ”€â”€ assets/                        # UI assets and sample images
â”œâ”€â”€ requirements.txt               # Python dependencies
â”œâ”€â”€ README.md                      # Project overview and guide
â””â”€â”€ .env                           # Your API keys (not pushed to GitHub)
```

---

## ğŸ” Project Flow

```
Voice Input â†’ Whisper Transcription (STT)
                â†“
       User Query (Text or Image)
                â†“
         GROQ + LLaMA 3 Vision
                â†“
         Text Response Generated
                â†“
        TTS via gTTS / ElevenLabs
                â†“
            Voice Output
                â†“
            Display in Gradio
```

---

## âš™ï¸ Installation & Setup

> Tested on Python 3.9+

### ğŸ” 1. Clone the Repository

```bash
git clone https://github.com/PataskarSharvari/ai-medical-chatbot.git
cd ai-medical-chatbot
```

### ğŸ“¦ 2. Create a Virtual Environment (optional but recommended)

```bash
python -m venv .venv
source .venv/bin/activate  # Windows: .venv\Scripts\activate
```

### ğŸ“¦ 3. Install Dependencies

```bash
pip install -r requirements.txt
```

### ğŸ”‘ 4. Add Your API Keys

Create a `.env` file and add the following:

```env
GROQ_API_KEY=your_groq_api_key
```

### ğŸ”Š 5. Install Required Audio Libraries

Install `ffmpeg` and `portaudio`:

- **Windows**: Use [FFmpeg builds](https://www.gyan.dev/ffmpeg/builds/) and install `portaudio` using `pip install pyaudio`.
- **Linux**: Use `sudo apt install ffmpeg portaudio19-dev`

---

## ğŸš€ How to Run Locally

```bash
python app.py
```

> A Gradio interface will launch in your browser at `http://localhost:7860`.

---

> For live demo, visit [WhisperHealth on Hugging Face](https://huggingface.co/spaces/SharvariPataskar/WhisperHealth-AI)

---

## ğŸ§© Dependencies

```txt
gradio
openai-whisper
pyaudio
ffmpeg
groq
gtts
elevenlabs
python-dotenv
```

---

## ğŸ“ˆ Roadmap & Future Improvements

- ğŸ’° Upgrade to state-of-the-art paid Vision LLMs (e.g. Gemini, Claude)
- ğŸ§  Finetune LLaMA-3 Vision model on medical datasets
- ğŸŒ Add multilingual support (Hindi, Marathi, etc.)
- ğŸ§¾ Store past interactions securely with MongoDB and add RAG (Retrieval-Augmented Generation) with medical knowledge base.
- ğŸ“± Mobile optimized frontend (React Native)

---

## ğŸ¤ Contributing

Pull requests and feature suggestions are welcome. Please open an issue first to discuss what you would like to change.

---

## ğŸ“œ License

MIT License

---

## ğŸ“¬ Contact

- ğŸ‘©â€ğŸ’» Developer: [Sharvari Pataskar](https://github.com/PataskarSharvari)
  
---

## âœ¨ Acknowledgements

- [Meta LLaMA 3 Vision](https://llama.meta.com/)
- [Groq API](https://console.groq.com/)
- [Gradio](https://www.gradio.app/)
- [OpenAI Whisper](https://github.com/openai/whisper)

